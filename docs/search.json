[
  {
    "objectID": "gpt4_sim.html",
    "href": "gpt4_sim.html",
    "title": "Comparing Humand and gpt4o Ratings of Image Similarity",
    "section": "",
    "text": "Wright-Stained white blood cell images from Trueblood et al. (2018)\n\nfine tuned representations from Holmes et al. (2020)\n\n\n\nDisplay code# bar plots with error bars for sim_trial_type\nhb &lt;- st_avg_type |&gt; ggplot(aes(x=sim_trial_type, y=mean_response, fill=sim_trial_type)) + \n  stat_summary(fun=mean, geom=\"bar\") +\n  stat_summary(fun.data=mean_se, geom=\"errorbar\", width=0.2) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(size=9,angle = 70, hjust = 1)) +\n  labs(title=\"Human Mean similarity ratings by trial type\", x=\"Trial type\", y=\"Mean human similarity rating\") \n\nhb\n\n\n\nHuman Ratings\n\n\nDisplay codeggplot(st_avg_type, aes(x = mean_response, y = reorder(image_pair, mean_response), col = sim_trial_type)) + \n  geom_point(size = 2) +\n  geom_errorbarh(aes(xmin = mean_response - sd(sim_trials$response) / sqrt(n), \n                     xmax = mean_response + sd(sim_trials$response) / sqrt(n)),\n                 height = 0.2) +\n  facet_wrap(~ sim_trial_type, scales = \"free_y\", ncol = 2) +\n  theme_minimal() +\n  theme(axis.text.y = element_text(size = 6),\n        strip.text = element_text(size = 10, face = \"bold\"),\n        legend.position = \"none\") +\n  labs(title = \"Mean similarity ratings by trial type\", \n       x = \"Mean similarity rating\", \n       y = \"Image Pair\") +\n  scale_x_continuous(limits = c(0, 10), breaks = seq(0, 10, 2))\n\n\n\nHuman Ratings",
    "crumbs": [
      "LLM",
      "gpt-4o similarity"
    ]
  },
  {
    "objectID": "gpt4_sim.html#inspect-human-ratings",
    "href": "gpt4_sim.html#inspect-human-ratings",
    "title": "Comparing Humand and gpt4o Ratings of Image Similarity",
    "section": "",
    "text": "Wright-Stained white blood cell images from Trueblood et al. (2018)\n\nfine tuned representations from Holmes et al. (2020)\n\n\n\nDisplay code# bar plots with error bars for sim_trial_type\nhb &lt;- st_avg_type |&gt; ggplot(aes(x=sim_trial_type, y=mean_response, fill=sim_trial_type)) + \n  stat_summary(fun=mean, geom=\"bar\") +\n  stat_summary(fun.data=mean_se, geom=\"errorbar\", width=0.2) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(size=9,angle = 70, hjust = 1)) +\n  labs(title=\"Human Mean similarity ratings by trial type\", x=\"Trial type\", y=\"Mean human similarity rating\") \n\nhb\n\n\n\nHuman Ratings\n\n\nDisplay codeggplot(st_avg_type, aes(x = mean_response, y = reorder(image_pair, mean_response), col = sim_trial_type)) + \n  geom_point(size = 2) +\n  geom_errorbarh(aes(xmin = mean_response - sd(sim_trials$response) / sqrt(n), \n                     xmax = mean_response + sd(sim_trials$response) / sqrt(n)),\n                 height = 0.2) +\n  facet_wrap(~ sim_trial_type, scales = \"free_y\", ncol = 2) +\n  theme_minimal() +\n  theme(axis.text.y = element_text(size = 6),\n        strip.text = element_text(size = 10, face = \"bold\"),\n        legend.position = \"none\") +\n  labs(title = \"Mean similarity ratings by trial type\", \n       x = \"Mean similarity rating\", \n       y = \"Image Pair\") +\n  scale_x_continuous(limits = c(0, 10), breaks = seq(0, 10, 2))\n\n\n\nHuman Ratings",
    "crumbs": [
      "LLM",
      "gpt-4o similarity"
    ]
  },
  {
    "objectID": "gpt4_sim.html#collect-gpt-4-ratings",
    "href": "gpt4_sim.html#collect-gpt-4-ratings",
    "title": "Comparing Humand and gpt4o Ratings of Image Similarity",
    "section": "Collect GPT-4 Ratings",
    "text": "Collect GPT-4 Ratings\n\nDisplay codeapi_key &lt;- Sys.getenv(\"OPENAI_API_KEY\")\n\n\nencode_image &lt;- function(image_path) {\n  image_data &lt;- readBin(image_path, what = \"raw\", n = file.info(image_path)$size)\n  base64_encoded &lt;- base64enc::base64encode(image_data)\n  encoded_image &lt;- glue::glue(\"data:image/jpeg;base64,{base64_encoded}\")\n  return(encoded_image)\n}\n\n\nget_gpt4_rating &lt;- function(image_path) {\n  tryCatch({\n    encoded_image &lt;- encode_image(image_path)\n\n    system_prompt &lt;- \"You are acting as a human research participant in a psychology study. You will be presented with an image that contains two cell images (one on the left, and the other on the right). Your task is to rate the similarity of the images, with 0 being not similar at all, and 10 being very similar. Respond only with the integer corresponding to your rating.\"\n\n    trial_instruction &lt;- \"Rate the similarity of these 2 images:\"\n\n    response &lt;- openai::create_chat_completion(\n      model = \"gpt-4o\",\n      temperature = 0.0,\n      top_p = 1,\n      frequency_penalty = 0,\n      messages = list(\n        list(\n          role = \"system\",\n          content = system_prompt\n        ),\n        list(role = 'user',\n            content = list(\n              list(\n                type = 'text',\n                text = trial_instruction\n              ),\n              list(\n                type = 'image_url',\n                image_url = list(\n                  url = encoded_image #, detail=\"low\"\n                )\n              )\n            )\n      )\n      )\n    )\n    return(response)\n  }, error = function(e) {\n    warning(paste(\"Error occurred while sending request to OpenAI API for image:\", image_path, \":\", e$message))\n    return(NULL)\n  })\n}\n\n# collect ratings using openai api - takes ~5 minutes for 240 images. \n\n# combined_df_with_ratings &lt;- st_avg %&gt;% mutate(gpt_response = map(path, get_gpt4_rating))\n\ncombined_df2 &lt;- combined_df_with_ratings %&gt;%\n  mutate(gpt4o_rating = map_dbl(gpt_response, ~ {\n    if (is.null(.x) || identical(.x, \"NULL\")) {\n      return(NA_real_)\n    } else {\n      # Extract the integer rating\n      rating &lt;- tryCatch(\n        {\n          rating_value &lt;- as.integer(str_extract(.x$choices$message.content, \"\\\\d\"))\n          if (is.na(rating_value)) {\n            NA_real_\n          } else {\n            rating_value\n          }\n        },\n        error = function(e) NA_real_\n      )\n      return(rating)\n    }\n  }))\n\n\n#saveRDS(combined_df2, here(\"first_full_run_script_list.rds\"))\n\nst_avg_type2 &lt;- st_avg_type |&gt; left_join(combined_df2 |&gt; select(image_pair,gpt4o_rating), by=c(\"image_pair\"))\n#saveRDS(st_avg_type2, here(\"data\",\"gpt4o_ratings.rds\"))\n\n\n# count combined_df2$gpt4o_rating equal to NA (3)\n#sum(is.na(combined_df2$gpt4o_rating))",
    "crumbs": [
      "LLM",
      "gpt-4o similarity"
    ]
  },
  {
    "objectID": "gpt4_sim.html#compare-human-and-gpt-4o-ratings",
    "href": "gpt4_sim.html#compare-human-and-gpt-4o-ratings",
    "title": "Comparing Humand and gpt4o Ratings of Image Similarity",
    "section": "Compare Human and GPT-4o Ratings",
    "text": "Compare Human and GPT-4o Ratings\nOverall correlation\n\nDisplay codest_avg_type2 &lt;- readRDS(here(\"data\",\"gpt4o_ratings.rds\"))\ncor(st_avg_type2$mean_response, st_avg_type2$gpt4o_rating, use=\"complete.obs\")\n\n[1] 0.2764047\n\n\nCorrelation by sim_trial_type\n\nDisplay code# compute cor separately for each level of sim_trial_type\nst_avg_type2 |&gt; \n  group_by(sim_trial_type) |&gt; \n  summarise(n=n(),correlation = cor(mean_response, gpt4o_rating, use = \"complete.obs\")) |&gt; \n  arrange(desc(correlation)) |&gt; kable()\n\n\n\nsim_trial_type\nn\ncorrelation\n\n\n\nexpected-supervised-notsimilar\n30\n0.8651824\n\n\nexpected-google_net-notsimilar\n30\n0.8354325\n\n\nrandom\n30\n0.7936983\n\n\nrepeat\n30\n0.7592152\n\n\nexpected-google_net-similar\n30\n0.6880413\n\n\ndisagreement-googlenet_not_supervised\n30\n0.6282894\n\n\ndisagreement-supervised_not_googlenet\n30\n0.3392075\n\n\nexpected-supervised-similar\n30\n0.1618294\n\n\nsame\n30\n0.0076130\n\n\n\n\n\nCorrelation after filtering out “same” trials\n\nDisplay code# filter out sim_trial_type == \"same\" and compute the correlation again\nst_avg_type2 |&gt; \n  filter(sim_trial_type != \"same\") |&gt;\n  with(cor(mean_response, gpt4o_rating, use = \"complete.obs\"))\n\n[1] 0.7453264\n\n\nCorrelation after filtering out human ratings greater than 7\n\nDisplay code# filter out human ratings greater than 7, and compute the correlation again\ncor(st_avg_type2 %&gt;%\n      filter(mean_response &lt;= 7) %&gt;%\n      pull(mean_response),\n    st_avg_type2 %&gt;%\n      filter(mean_response &lt;= 7) %&gt;%\n      pull(gpt4o_rating),\n    use = \"complete.obs\")\n\n[1] 0.7785929\n\n\n\nDisplay codegptb &lt;- st_avg_type2 |&gt; ggplot(aes(x=sim_trial_type, y=gpt4o_rating, fill=sim_trial_type)) + \n  stat_summary(fun=mean, geom=\"bar\") +\n  stat_summary(fun.data=mean_se, geom=\"errorbar\", width=0.2) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(size=9,angle = 70, hjust = 1)) +\n  labs(title=\"gpt4o - Mean similarity ratings by trial type\", x=\"Trial type\", y=\"Mean gpt4 similarity rating\") \n\n# combine and collect legend\nhb+gptb + plot_layout(guides = \"collect\")\n\n\n\nRating comparison - by trial type\n\n\n\n\nDisplay codest_avg_type2 %&gt;%\n  mutate(mean_resp_bin = cut(mean_response, breaks = c(0,1, 2, 3, 4, 5, 6, 7, 8, 9, 10), include.lowest = TRUE)) %&gt;%\n  ggplot(aes(mean_resp_bin, gpt4o_rating)) +\n  geom_boxplot() +\n  theme_minimal() +\n  labs(title = \"Boxplot of GPT-4 Ratings by Human Ratings\",\n       x = \"Human Ratings Bin\", y = \"GPT-4 Ratings\") +\n  scale_x_discrete(name = \"Human Ratings\", labels = 1:9)\n\n\n\nRating comparison - all images\n\n\n\n\nDisplay codep1 &lt;- st_avg_type2 %&gt;%\n  filter(sim_trial_type != \"same\") %&gt;%\n  mutate(mean_resp_bin = cut(mean_response, breaks = c(0,1, 2, 3, 4, 5, 6, 7, 8, 9, 10), include.lowest = TRUE)) %&gt;%\n  ggplot(aes(mean_resp_bin, gpt4o_rating)) +\n  geom_boxplot() +\n  theme_minimal() +\n  labs(title = \"Boxplot of GPT-4 Ratings by Human Ratings\",\n       x = \"Human Ratings Bin\", y = \"GPT-4 Ratings\") +\n  scale_x_discrete(name = \"Human Ratings\", labels = 1:9)\n\n\n# scatter plot of human vs gpt-4 ratings\np2 &lt;- st_avg_type2 %&gt;%\n  filter(sim_trial_type != \"same\") %&gt;%\n  ggplot(aes(x=mean_response, y=gpt4o_rating)) +\n  geom_point() +\n  geom_smooth(method=\"lm\") +\n  theme_minimal() +\n  labs(title=\"Human vs GPT-4 Ratings\", x=\"Human Ratings\", y=\"GPT-4 Ratings\") +\n  scale_x_continuous(limits=c(0, 10), breaks=seq(0, 10, 2)) +\n  scale_y_continuous(limits=c(0, 10), breaks=seq(0, 10, 2))\n\np1 + p2\n\n\n\nRating comparison - remove “same” ratings\n\n\n\n\nDisplay codest_avg_type2 %&gt;%\n  mutate(mean_resp_bin = cut(mean_response, breaks = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), include.lowest = TRUE)) %&gt;%\n  ggplot(aes(mean_resp_bin, gpt4o_rating)) +\n  geom_boxplot() +\n  facet_wrap(~ sim_trial_type) +\n  theme_minimal() +\n  labs(title = \"Boxplot of GPT-4 Ratings by Human Ratings\",\n       x = \"Human Ratings Bin\", y = \"GPT-4 Ratings\") +\n  scale_x_discrete(name = \"Human Ratings\", labels = 1:9)\n\n\n\nRating distributions\n\n\nDisplay codest_avg_type2 |&gt; ggplot(aes(x=mean_response, y=gpt4o_rating, col=sim_trial_type)) + \n  geom_point() +\n  geom_smooth(method=\"lm\") +\n  facet_wrap(~sim_trial_type) +\n  theme_minimal() +\n  labs(title=\"Human vs GPT-4 Ratings\", x=\"Human Ratings\", y=\"GPT-4 Ratings\") +\n  scale_x_continuous(limits=c(0, 10), breaks=seq(0, 10, 2)) +\n  scale_y_continuous(limits=c(0, 10), breaks=seq(0, 10, 2))\n\n\n\nRating distributions\n\n\n\nEffect of Rotation\n\nDisplay codest_avg_type2 |&gt; \n  filter(sim_trial_type %in% c(\"same\",\"repeat\")) |&gt;\n  ggplot(aes(x=mean_response, y=gpt4o_rating, col=sim_trial_type)) + \n  geom_point() +\n  geom_smooth(method=\"lm\") +\n  facet_wrap(rotation~sim_trial_type) +\n  theme_minimal() +\n  labs(title=\"Human vs GPT-4 Ratings\", x=\"Human Ratings\", y=\"GPT-4 Ratings\") +\n  scale_x_continuous(limits=c(0, 10), breaks=seq(0, 10, 2)) +\n  scale_y_continuous(limits=c(0, 10), breaks=seq(0, 10, 2))\n\n\n\n\n\n\nDisplay codest_avg_type2 |&gt; \n  filter(sim_trial_type %in% c(\"same\",\"repeat\")) |&gt;\n    group_by(sim_trial_type,rotation) |&gt; \n  summarise(n=n(),correlation = cor(mean_response, gpt4o_rating, use = \"complete.obs\")) |&gt; \n  arrange(desc(correlation)) |&gt; kable()\n\n\n\nsim_trial_type\nrotation\nn\ncorrelation\n\n\n\nrepeat\n180\n2\n1.0000000\n\n\nrepeat\n0\n26\n0.7853568\n\n\nsame\n180\n14\n0.0823603\n\n\nsame\n270\n9\n0.0724394\n\n\nsame\n90\n7\n-0.1319488\n\n\nrepeat\n270\n2\nNA",
    "crumbs": [
      "LLM",
      "gpt-4o similarity"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Dot Pattern Similarity Project",
    "section": "",
    "text": "Comparing Humand and gpt4o Ratings of Image Similarity\n\n\n\n\n\n\n\n\n\nJul 6, 2024\n\n\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Home"
    ]
  }
]